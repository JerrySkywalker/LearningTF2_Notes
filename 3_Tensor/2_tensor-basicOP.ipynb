{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2.0.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 张量的基本运算\n",
    "（可能和前文有一些重复）\n",
    "在tensorflow2.0中，数学运算全部都被移动到了tf.math下。当然原来的API还有一些保留\n",
    "\n",
    "本节目标：了解tf2中张量的基本运算。\n",
    "- 基本运算(按元素)（方法、操作符两种方式）\n",
    "    - 加\n",
    "    - 减\n",
    "    - 乘\n",
    "    - 除法    \n",
    "    - 地板除法  (API变更)\n",
    "    - 取余    (API变更)\n",
    "- 指数、开方、对数\n",
    "- 矩阵"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 基本运算：（+、-、*、/、//、%）\n",
    "基本运算中所有实例都以下面的张量a、b为例进行："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "a = tf.random.uniform([2, 3], minval=1, maxval=6,dtype=tf.int32)\n",
    "b = tf.random.uniform([2, 3], minval=1, maxval=6,dtype=tf.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=3, shape=(2, 3), dtype=int32, numpy=\narray([[4, 4, 4],\n       [1, 3, 5]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=7, shape=(2, 3), dtype=int32, numpy=\narray([[5, 2, 5],\n       [1, 4, 4]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（1）加（+）**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=8, shape=(2, 3), dtype=int32, numpy=\narray([[9, 6, 9],\n       [2, 7, 9]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "tf.add(a,b)  # 通过add方法执行加操作"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=9, shape=(2, 3), dtype=int32, numpy=\narray([[9, 6, 9],\n       [2, 7, 9]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "a + b  # 也可以通过操作符进行"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（2）减（-）**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=10, shape=(2, 3), dtype=int32, numpy=\narray([[-1,  2, -1],\n       [ 0, -1,  1]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "tf.subtract(a,b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=11, shape=(2, 3), dtype=int32, numpy=\narray([[-1,  2, -1],\n       [ 0, -1,  1]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "a - b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（3）乘法（*）**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=12, shape=(2, 3), dtype=int32, numpy=\narray([[20,  8, 20],\n       [ 1, 12, 20]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "tf.multiply(a,b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=13, shape=(2, 3), dtype=int32, numpy=\narray([[20,  8, 20],\n       [ 1, 12, 20]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "a * b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（4）除法（/）**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=16, shape=(2, 3), dtype=float64, numpy=\narray([[0.8 , 2.  , 0.8 ],\n       [1.  , 0.75, 1.25]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "tf.divide(a,b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=19, shape=(2, 3), dtype=float64, numpy=\narray([[0.8 , 2.  , 0.8 ],\n       [1.  , 0.75, 1.25]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "a/b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（5）地板除法（//）**\n",
    "针对浮点数的除法向下取整。\n",
    "\n",
    "与整数的tf.div（x，y）相同，但对浮点参数使用tf.math.floordiv（tf.div（x，y）），以便结果始终为整数（尽管可能是表示为浮点的整数））。 此操作由Python 3中的x // y floor division和带有__future__ import division的Python 2.7生成。\n",
    "\n",
    "请注意，为了提高效率，floordiv对负数使用C语法（与Python和Numpy不同）。\n",
    "\n",
    "**API变更：官方将tf.floor_div 移动到 tf.math.floordiv**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=20, shape=(2, 3), dtype=int32, numpy=\narray([[0, 2, 0],\n       [1, 0, 1]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "#tf.floor_div(a,b)\n",
    "tf.math.floordiv(a,b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=21, shape=(2, 3), dtype=int32, numpy=\narray([[0, 2, 0],\n       [1, 0, 1]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "a // b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（6）取余（%）**\n",
    "\n",
    "**API变更：官方将tf.mod 移动到 tf.math.mod**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=22, shape=(2, 3), dtype=int32, numpy=\narray([[1, 2, 1],\n       [0, 1, 4]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "#tf.mod(b,a)\n",
    "tf.math.mod(b,a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=23, shape=(2, 3), dtype=int32, numpy=\narray([[1, 2, 1],\n       [0, 1, 4]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "b % a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看出，对于基本运算加（+）、减（-）、点乘（*）、除（/）、地板除法（//）、取余（%），都是对应元素进行运算。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 指数、开方、对数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（1）对数运算**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TensorFlow提供tf.math.log()方法来求对数，当然，求的是以自然常数$e$为底的对数："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=25, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "e = 2.71828183\n",
    "a = tf.constant([e, e*e, e*e*e])\n",
    "tf.math.log(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=29, shape=(2, 2), dtype=float32, numpy=\narray([[0., 0.],\n       [0., 0.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "c = tf.fill([2,2],1.)\n",
    "tf.math.log(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意：TensorFlow中没有提供函数实现以其他数值为底的对数运算，所以求其他对数的时候需要用换底公式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$lo{g_a}b = \\frac{{lo{g_c}b}}{{lo{g_c}a}}$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "所以有："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "f = tf.constant([[1., 9.], [16., 100.]])\n",
    "g = tf.constant([[2., 3.], [2., 10.]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=34, shape=(2, 2), dtype=float32, numpy=\narray([[0., 2.],\n       [4., 2.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "tf.math.log(f) / tf.math.log(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（2）指数运算**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "g = tf.constant([[2, 3], [2, 10]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=37, shape=(2, 2), dtype=int32, numpy=\narray([[  4,   9],\n       [  4, 100]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "tf.pow(g, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "也可以直接通过运算符来完成："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=39, shape=(2, 2), dtype=int32, numpy=\narray([[  4,   9],\n       [  4, 100]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "g ** 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**（3）开方**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "f = tf.constant([[1., 9.], [16., 100.]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=41, shape=(2, 2), dtype=float32, numpy=\narray([[ 1.,  3.],\n       [ 4., 10.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "tf.sqrt(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "自然常数$e$的指数运算："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "d = tf.constant([[1.,2.],[3.,4.]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=43, shape=(2, 2), dtype=float32, numpy=\narray([[ 2.7182817,  7.389056 ],\n       [20.085537 , 54.59815  ]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 27
    }
   ],
   "source": [
    "tf.exp(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意：对数运算函数log()与指数运算函数在不同的模块中。\n",
    "\n",
    "在我看来，上面提到的指数运算与对数运算不在通知模块以及没有提供以其他自然数为底的对数运算，应该应该是TensorFlow中的遗留问题，希望能够在正式版中得到修正。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 矩阵相乘"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = tf.constant(np.arange(6),shape=(2,3))\n",
    "b = tf.constant(np.arange(6),shape=(3,2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=46, shape=(2, 3), dtype=int32, numpy=\narray([[0, 1, 2],\n       [3, 4, 5]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=49, shape=(3, 2), dtype=int32, numpy=\narray([[0, 1],\n       [2, 3],\n       [4, 5]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 30
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=50, shape=(2, 2), dtype=int32, numpy=\narray([[10, 13],\n       [28, 40]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ],
   "source": [
    "tf.matmul(a,b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "矩阵相乘也可以通过符号来操作进行，用“@”表示："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=51, shape=(2, 2), dtype=int32, numpy=\narray([[10, 13],\n       [28, 40]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 32
    }
   ],
   "source": [
    "a @ b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里的张量a和b都是二维的，但在实际应用中，数据往往高于二维，这时候怎么应算呢？"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "a = tf.constant(np.arange(12),shape=(2,2,3))\n",
    "b = tf.constant(np.arange(12),shape=(2,3,2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=54, shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 0,  1,  2],\n        [ 3,  4,  5]],\n\n       [[ 6,  7,  8],\n        [ 9, 10, 11]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 34
    }
   ],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=57, shape=(2, 3, 2), dtype=int32, numpy=\narray([[[ 0,  1],\n        [ 2,  3],\n        [ 4,  5]],\n\n       [[ 6,  7],\n        [ 8,  9],\n        [10, 11]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=58, shape=(2, 2, 2), dtype=int32, numpy=\narray([[[ 10,  13],\n        [ 28,  40]],\n\n       [[172, 193],\n        [244, 274]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 36
    }
   ],
   "source": [
    "a @ b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，当高于二维的张量进行矩阵相乘时，最终的实现还是二维矩阵相乘，只不过分成了多个二维矩阵，四维张量也是一样的："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "a = tf.constant(np.arange(24),shape=(2,2,2,3))\n",
    "b = tf.constant(np.arange(24),shape=(2,2,3,2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=65, shape=(2, 2, 2, 2), dtype=int32, numpy=\narray([[[[  10,   13],\n         [  28,   40]],\n\n        [[ 172,  193],\n         [ 244,  274]]],\n\n\n       [[[ 550,  589],\n         [ 676,  724]],\n\n        [[1144, 1201],\n         [1324, 1390]]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 38
    }
   ],
   "source": [
    "a @ b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 Broadcasting机制"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面的所有实例中所用到的张量都是在维度数和形状相同情况下进行，当两个张量维度数或者形状不一样时，也可以进行计算。这里引入了一个机制叫做广播(BroadCasting)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "a = tf.constant([1,2,3])\n",
    "b = tf.constant(np.arange(12),shape=(2,2,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=69, shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 0,  1,  2],\n        [ 3,  4,  5]],\n\n       [[ 6,  7,  8],\n        [ 9, 10, 11]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 40
    }
   ],
   "source": [
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=70, shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 1,  3,  5],\n        [ 4,  6,  8]],\n\n       [[ 7,  9, 11],\n        [10, 12, 14]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 41
    }
   ],
   "source": [
    "a + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=71, shape=(2, 2, 3), dtype=int32, numpy=\narray([[[ 0,  2,  6],\n        [ 3,  8, 15]],\n\n       [[ 6, 14, 24],\n        [ 9, 20, 33]]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 42
    }
   ],
   "source": [
    "a * b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，一个一维的张量与一个三维张量进行运算是完全没有问题的，从运算结果上可以看出，相当于是三维张量中的每一行数据与张量a进行运算，为什么可以这样运输呢？这就得益于TensorFlow中的Broadcasting机制。\n",
    "\n",
    "Broadcasting机制解除了只能维度数和形状相同的张量才能进行运算的限制，当两个数组进行算术运算时，TensorFlow的Broadcasting机制首先对维度较低的张量形状数组填充1，从后向前，逐元素比较两个数组的形状，当逐个比较的元素值（注意，这个元素值是指描述张量形状数组的值，不是张量的值）满足以下条件时，认为满足 Broadcasting 的条件：\n",
    "\n",
    "（1）相等\n",
    "\n",
    "（2）其中一个张量形状数组元素值为1。\n",
    "\n",
    "当不满足时进行运算则会抛出 ValueError: frames are not aligne 异常。算术运算的结果的形状的每一元素，是两个数组形状逐元素比较时的最大值。\n",
    "\n",
    "回到上面张量a与b相乘的例子，a的形状是（3，），b的形状是(2, 2, 3)，在Broadcasting机制工作时，首先比较维度数，因为a的维度为1，小于b的维度3，所以填充1，a的形状就变成了（1,1,3），然后从最后端的形状数组元素依次往前比较，先是就是3与3比，结果是相等，接着1与2相比，因为其中一个为1，所以a的形状变成了（1,2,3），继续1与2比较，因为其中一个为1，所以a的形状变成了（2,2,3），a中的数据每一行都填充a原来的数据，也就是[1,2,3]，然后在与b进行运算。\n",
    "\n",
    "当然，在TensorFlow的Broadcasting机制运行过程中，上述操作只是理论的，并不会真正的将a的形状变成（2,2,3,），更不会将每一行填充[1,2,3]，只是虚拟进行操作，真正计算时，依旧是使用原来的张量a。这么做的好处是运算效率更高，也更节省内存。\n",
    "\n",
    "最后总结以下广播的机制：\n",
    "- 1. 比较总的维度，如果不相等，进行2；如果相等，按照元素相乘\n",
    "- 2. **从后往前比较形状(这里最关键)**，如果成倍数，则进行广播操作，进行扩容；如果不成倍数，则失败，抛出异常\n",
    "\n",
    "\n",
    "再举一些例子加深理解："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [ ] A：(2d array): 5 x 4  \n",
    "- [ ] B：(1d array): 1  \n",
    "- [ ] Result：(2d array): 5 x 4  \n",
    "---\n",
    "- [ ] A：(2d array): 5 x 4   \n",
    "- [ ] B：(1d array): 4    \n",
    "- [ ] Result：(2d array): 5 x 4 \n",
    "---\n",
    "- [ ] A：(3d array): 15 x 3 x 5   \n",
    "- [ ] B：(3d array): 15 x 1 x 5  \n",
    "- [ ] Result：(3d array): 15 x 3 x 5\n",
    "---\n",
    "- [ ] A：(3d array): 15 x 3 x 5   \n",
    "- [ ] B：(2d array): 3 x 5   \n",
    "- [ ] Result：(3d array): 15 x 3 x 5\n",
    "---\n",
    "- [ ] A：(3d array): 15 x 3 x 5  \n",
    "- [ ] B：(2d array): 3 x 1  \n",
    "- [ ] Result：(3d array): 15 x 3 x 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "一些反例（不满足 Broadcasting 规则 ）："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [ ] A (1d array): 3    \n",
    "- [ ] B (1d array): 4   \n",
    "---\n",
    "- [ ] A (2d array): 2 x 1    \n",
    "- [ ] B (3d array): 8 x 4 x 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 范数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "范数是泛函分析中的概念，指的是一种更宽泛的长度（距离）概念，只要满足非负、自反、三角不等式就可以称之为距离。向量$v$的$p$范数可以使用下面公式进行计算：\n",
    "\n",
    "$$|v|{|_p} = {\\left[ {\\sum\\limits_{k = 1}^N {|{v_k}|p} } \\right]^{1/p}}$$\n",
    "\n",
    "当$p = 1,2$时分别叫做1范数，2范数。除此以外，还有无穷范数：\n",
    "$$|v|{|_{ + \\infty }} = \\max (|v(i)|)$$\n",
    "$$|v|{|_{ - \\infty }} = \\min (|v(i)|)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "a = tf.constant([[1.,2.],[1.,2.]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=76, shape=(), dtype=float32, numpy=6.0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 44
    }
   ],
   "source": [
    "tf.norm(a, ord=1)  # 1范数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=81, shape=(), dtype=float32, numpy=3.1622777>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 45
    }
   ],
   "source": [
    "tf.norm(a, ord=2)  # 2范数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=86, shape=(), dtype=float32, numpy=3.1622777>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 46
    }
   ],
   "source": [
    "tf.norm(a)  # ord不指定时，默认是2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们也可以全手动地实现范数："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=90, shape=(), dtype=float32, numpy=3.1622777>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 47
    }
   ],
   "source": [
    "tf.sqrt(tf.reduce_sum(tf.square(a)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "指定维度求范数："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=95, shape=(2,), dtype=float32, numpy=array([1.4142135, 2.828427 ], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 48
    }
   ],
   "source": [
    "tf.norm(a, ord=2, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=100, shape=(2,), dtype=float32, numpy=array([2.236068, 2.236068], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 49
    }
   ],
   "source": [
    "tf.norm(a, ord=2, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python361064bitenvgpucondad97e9682d1cf4c0fab2709094ecbe611",
   "language": "python",
   "display_name": "Python 3.6.10 64-bit ('env_gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}