# 机器学习基础

本节介绍机器学习的一些基础概念

## 1.学习算法

### 1.1基础概念

- 学习：对于某类任务$T$和性能度量$P$，经过经验$E$的改进，$T,P$会有一定程度的提升
- 任务：即我们要实现的具体目标
  - 描述任务的方式
    - 样本：特征的集合
    - 特征
  - 常见的任务种类
    - 分类
    - 输入缺失分类
    - 回归
    - 转录
    - 机器翻译
    - 结构化输出(eg.语法分析)
    - 异常检测
    - 合成和采样
    - 缺失值填补
    - 去噪
    - 密度估计和质量函数估计
- 性能度量：评估任务完成情况的函数
  - 常见的性能度量
    - 准确率
    - 错误率
  - 使用测试集
  - 设计取决于应用(指标粗粒度/细粒度?惩罚程度?)
  - 可采用替代标准或良好近似
- 经验E
  - 无监督学习：学习出数据集的有用的结构性质(显式或隐式)
  - 监督学习：通过数据集上的标签，推测分类标准
  - 区别：无监督学习得到$p(x)$，监督学习得出$p(y|x)$
  - 监督学习和无监督学习可以相互转化(全概率公式、贝叶斯公式)
  - 设计矩阵：数据集的常用表示方法。设计矩阵的每一行包含一个不同的样本，每一列代表不同的特征。

### 1.2实例：线性回归

线性回归是一类最常见的，也是最简单的学习算法的使用领域，其有助于我们回顾整个学习算法的来龙去脉。

#### 1.2.1一般形式

一般的线性回归模型如下：
$$
\hat{y}=w^{\top} x+b
$$

- $w$：权重
- $b$：偏置
- $y(x)$：这是一个从特征到预测的一个映射，称为仿射函数

### 1.2.2 度量

假设我们有一个设计矩阵，不用它来训练，而仅用它来评估性能，我们称之为测试集。

一种常用方式是计算测试集上的均方误差(Mean Squared Error,MSE)
$$
\text { MSE }_{\text {test }}=\frac{1}{m} \sum_{i}\left(\hat{y}^{(\text {test })}-y^{(\text {test })}\right)_{i}^{2}
$$
显然，
$$
\mathrm{MSE}_{\text {test }}=\frac{1}{m}\left\|\hat{y}^{(\text {test })}-y^{(\text {test })}\right\|_{2}^{2}
$$

构建一个机器学习算法的思路如下：通过观察训练集$\left(X^{(\text {train })}, y^{(\text {train })}\right)$获得经验，减少$\operatorname{MSE}_{\text {test}}$，以改进权重$w$。

减少$MSE_{test}$，我们可以简化模型，仅理解为求其导数为零的情况，以下进行一些推导：
$$
\begin{aligned} \nabla_{w} \operatorname{MSE}_{\text {train }}=0 \\ \Rightarrow \nabla_{w} \frac{1}{m}\left\|\hat{y}^{(\text {train })}-y^{(\text {train })}\right\|_{2}^{2}=0 \\ \Rightarrow \frac{1}{m} \nabla_{w}\left\|X^{(\text {train })} w-y^{(\text {train })}\right\|_{2}^{2}=0 \\ \Rightarrow \nabla_{w}\left(X^{(\text {train })} w-y^{(\text {train })}\right)^{\top}\left(X^{(\text {train })} w-y^{(\text {train })}\right)=0 \\ \Rightarrow 2 X^{(\text {train })} w-2 w^{\top} X^{(\text {train }) \top} y^{(\text {train }) \top} y^{(\text {train })}=0 \\ \Rightarrow w=\left(X^{(\text {train })}\right)^{-1} X^{(\text {train }) \top} y^{(\text {train })} \end{aligned}
$$

由此推到的$w$称为正规方程。

## 2.为何能够“学习”：容量，过拟合和欠拟合

机器学习的主要挑战是：算法能够在先前未观测到新输入上表现良好。这种能力称为泛化能力。

这牵扯到两种误差：

- 训练误差：在训练集上使用，我们训练时的目的是降低训练误差
- 泛化误差/测试误差：我们真正关心的误差，即在面对未观测过的输入时，做出的判断误差尽量小

统计学习理论研究的就是这两种误差之间的关系。其告诉我们一个简单的道理：如果训练集和测试集是随意收集的，我们能够做的很有限；但如果对于训练集和测试集的收集方式有一定的假设，我们能够得到一些有趣的结论。

### 2.1 统计学习理论的基础概念

- 数据生成过程：训练集和测试集通过被称为~的概率分布生产
- 独立同分布假设
  - 相互独立
  - 同分布
- 数据生成分布
  - 在独立同分布的情况下，数据集和测试集可以共享这个潜在分布，称为数据生成分布

数据生成分布和独立同分布假设允许我们在数学上研究训练误差和测试误差之间的联系。

### 2.2 评价学习算法的两个依据和异常状态

评价学习算法的两个依据是：

1. 降低训练误差
2. 缩小训练误差和测试误差之间的差距

与两个评价标准分别对应，我们定义两个学习算法效果不佳时的状态：

1. 欠拟合：模型不能再训练集上获得足够低的误差
2. 过拟合：训练误差和测试误差之间的差距过大

### 2.3 容量和假设空间

- 容量：通俗来讲，容量指的是其拟合函数的能力。改变容量额方法有很多，例如多项式次数，参数个数等。容量不仅取决于模型的选择。
  - 表示容量：模型规定了可以从那些函数族中选择函数
  - 有效容量：一个可以大大降低训练误差的函数族的容量。有时，有效容量小于表示容量
  - 最优容量：若小于最优容量太多时是欠拟合的，若大于最优容量太多时是过拟合的
- 假设空间：与容量相对应，即学习算法可以选择未解决方案的函数集。

在表示容量中找到一个完美函数往往是困难的，一般我们退而求其次，选择在有效容量中找一个效果较好的函数。

这说明：泛化是区别最优化和机器学习的最本质区别。

### 2.4 合适的容量？几条原则

- 奥卡姆剃刀原则：“在同样能够解释一个现象的理论中，选那个最简单的”。这条原则早在托勒密时代就被提出，在20世纪被概率论创始人形式化和精确化。
- 量化模型的容量
  - Vapnik-Chervonenkis维度(VC维)：VC维度量二元分类器的容量，最有名的量化模型的容量的方法之一。
  - 量化模型的容量使得统计学理论可以量化预测
    - 重要结论：训练误差和泛化误差之间差异的上界随着模型容量的增长而增长，随着训练样本的增多而下降。其实际关系类似一个u型曲线，这意味着其存在一个最优容量
  - 对于学习算法的指导有限，所以应用相对较少

对于复杂的问题，我们往往无法去确定最恰当的模型容量。为了充分性，我们往往选择模型容量大在训练集上进行训练。显然此时过拟合问题便成了我们主要需要克服的问题。

### 2.5 没有免费午餐定理

    以下参考：    https://blog.csdn.net/u013238941/article/details/79091252

定理的文字表述有以下几个版本：

- 若对于某些问题算法$L_a$学得的模型更好，那么必然存在另一些问题，这里算法$L_b$学得的模型更好
- 在所有数据生成分布平均之后，每个分类算法在未事观测的点上都有着相同的错误率

其数学表述为：
$$
E_{o t e}\left(L_{a} | X, f\right)=\sum_{h} \sum_{x \in \chi-X} P(x) \mathbb{I}(h(x)=f(x)) P\left(h | X, L_{a}\right)
$$

- $E_{ote}$：训练集外误差(off-training error,ote)的期望
- $\chi$：样本空间(样本的属性张成的空间)
- $H$：假设空间
- $L_a$：学习算法。学习算法有其偏好性，对于相同的训练数据，不同的学习算法可以产生不同的假设，学得不同的模型，因此才会有那个学习算法对于具体问题更好的问题
- $P\left(h | X, L_{a}\right)$：算法$L_a$​基于训练数据$X$产生假设$h$的概率
- $f$：代表希望学得的真实目标函数，要注意这个函数也不是唯一的，而是存在一个函数空间，在这个空间中按某个概率分布

显然，期望的表达式中关于没有具体算法的，所以是算法是与期望无关，这就是没有免费午餐定理。

没有免费午餐定理暗示我们必须在特定任务上设计机器学习算法。我们应当建立一种偏好来达到这种要求，而当这种偏好和我们希望解决的学习问题相吻合时效果更好

### 2.6 正则化

类似于奥卡姆剃刀的原则（并非只有这一种原则，比如引入一些先验知识，或者说奥卡姆就是先验知识的一种）可以由模型的结构直接实现（通过改变模型的结构，使模型最后的解趋于简单化），我们称之为模型的归纳偏好。(inductive bias)

而人为的给模型编入先验知识，即增加归纳偏好的过程称为正则化

- 正则化：修改学习模型，使其降低泛化误差而非训练误差
  - 权重衰减：线性回归问题常用方法

## 3 超参数和验证集

- 超参数：超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。
- 验证集：用于挑选超参数的数据子集称为验证集

### 3.1 交叉验证

将一个数据集分成固定的训练集和测试集，若测试机的误差很小，这将是有问题的。

为避免这种情况，一种朴素想法是：在原始数据上随机采样或分离出不同数据集上训练和测试应的部分。其引出了一种常见做法：`k-折交叉验证法`。

## 4.估计，偏差，方差

本节简单回顾统计学方面的相关工具

### 4.1点估计

- 点估计/统计量

$$
\hat{\boldsymbol{\theta}}_{m}=g\left(\boldsymbol{x}^{(1)}, \cdots, \boldsymbol{x}^{(m)}\right)
$$

- 函数估计

### 4.2.偏差

- 估计的偏差

$$
\operatorname{bias}\left(\hat{\boldsymbol{\theta}}_{m}\right)=\mathbb{E}\left(\hat{\boldsymbol{\theta}}_{m}\right)-\boldsymbol{\theta}
$$

- 无偏的

$$
\operatorname{bias}\left(\hat{\boldsymbol{\theta}}_{m}\right)=0
$$

- 渐进无偏的 

$$
\lim _{m \rightarrow \infty} \operatorname{bias}\left(\hat{\boldsymbol{\theta}}_{m}\right)=0
$$

### 4.3.方差和标准差

- 方差

$$
\operatorname{Var}(\hat{\theta})
$$

- 标准差

$$
\operatorname{SE}(\hat{\theta})
$$

估计量的方差和标准差告诉我们，当独立的从潜在的数据生成过程中重采样数据集时，如何让期望估计的变化，正如我们期望估计的偏差越小，其方差、标准差也应越小。

均值额标准差在机器学习中非常有用。我们通常用测试集样本的误差均值来估计泛化误差。

### 4.4.权衡偏差和方差以最小化均方误差

偏差和方差度量着估计量的两个不同的误差来源：

- 偏差：度量偏离真实函数或参数的误差
- 方差：度量数据上任意特定采样可能导致的估计期望的偏差

所以如何权衡这两种误差的影响呢？

- 交叉检验：一种最简单方法是交叉验证。经过实践检验证实，交叉验证在真实世界的许多任务上表现都很理想。

- 均方误差：另一种方法是比较这些估计的均方误差(Mean Squared Error,MSE)，其度量着估计和真实参数之间平方误差的总体期望误差。

$$
\begin{array}{l}{\mathrm{MSE} =\mathrm{E}\left[\left(\hat{\theta}_{m}-\theta\right)^{2}\right]} \\ { =\operatorname{Bias}\left(\hat{\theta}_{m}\right)^{2}+\operatorname{Var}\left(\hat{\theta}_{m}\right)}\end{array}
$$

需要特别注意的是，偏差和方差的关系和机器学习中的容量，过拟合，欠拟合的概念紧密相连。

用MSE来度量泛化误差(偏差和方差对于泛化误差都是有意义的)时，增加容量会增加方差，减小偏差。

### 4.5.一致性

我们期望，当数据集中的数据点数量增加时，点估计会收敛于参数的真实值，即：

$$
\text { plim }_{m \rightarrow \infty} \hat{\theta}_{m}=\theta
$$

这称为“一致性”。有时它指的是若一致性，有时它指强一致性——几乎必然收敛

一致性保证了估计量的偏差会随着数据样本数目的增多而减少。反之则不然——渐进无偏并不一定意味着一致性。

## 5.最大似然估计

### 5.1 一般的最大似然估计

我们希望有些准则可以让我们从不同模型中得到特定的函数作为好的估计，而不是猜测某些函数可能是好的估计。

最常用的准则时最大似然估计。

- 定义：对于$\mathrm{X}=\left\{x^{(1)}, \cdots, x^{(m)}\right\}$，独立的由未知的真实数据生成分布$p_{\mathrm{data}(X)}$生成。令$p_{\mathrm{data}(X;\theta)}$是一族由参数$\theta$确定的在相同空间上的概率分布，则对于$\theta$的最大似然估计为：
  
$$
\begin{aligned} \theta_{\mathrm{ML}} &=\underset{\theta}{\arg \max } p_{\text {model }}(\mathrm{X} ; \boldsymbol{\theta}) \\ &=\underset{\boldsymbol{\theta}}{\arg \max } \prod_{i=1}^{m} p_{\text {model }}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right) \end{aligned}
$$

- 为简便计算，一般将其化为对数形式（求和形式）：

$$
\theta_{\mathrm{ML}}=\arg \max _{\theta} \sum_{i=1}^{m} \log p_{\text {model }}\left(x^{(i)} ; \theta\right)
$$

- 因为当重新缩放代价函数时$\mathrm{argmax}$不会改变，我们可以除以$\mathrm{m}$以得到和训练数据经验分布$\hat{p}_{\mathrm{data}}$相关的期望作为准则

$$
\theta_{\mathrm{ML}}=\arg \max _{\theta} \mathbb{E}_{\mathbf{x} \sim p_{\text {data }}} \log p_{\text {model }}(\boldsymbol{x} ; \boldsymbol{\theta})
$$

- KL散度：一种解释最大似然估计的观点是将它看成最小化训练集上的经验分布$\hat{p}_{\mathrm{data}}$和模型分布之间的差异。两者之间的差异大小用KL散度来度量，其定义如下。由于左边一项仅与数据生成过程有关，和模型无关，这意味着当训练模型的KL散度最小化时，只需使得
$-\mathbb{E}_{\mathbf{x} \sim \hat{p}_{\text {data }}}\log p_{\text {model }}(\boldsymbol{x})$
最小即可。

$$
D_{\mathrm{KL}}\left(\hat{p}_{\text {data }} \| p_{\text {model }}\right)=\mathbb{E}_{\mathbf{x} \sim \hat{p}_{\text {data }}}\left[\log \hat{p}_{\text {data }}(\boldsymbol{x})-\log p_{\text {model }}(\boldsymbol{x})\right]
$$

需要注意的时，虽然最优$\theta$在最大化似然和最小化KL散度时是相同的，但目标函数的值是不同的。在软件中，我们通常将两者都称为最小化代价函数。因此最大化似然变成了最小化负对数似然(NLL)，或者等价的最小化交叉熵。

### 5.2 条件对数似然和均方误差

将最大似然估计推广到条件概率上是很简单的。而这也是监督学习的基础。

如果$X$表示所有的输入，$Y$表述我们观测到的目标，那么条件的最大似然估计为：

$$
\theta_{\mathrm{ML}}=\arg \max _{\theta} P(Y | X ; \theta)
$$

如果假设是独立同分布的，那么可以将上式分解为：

$$
\theta_{\mathrm{ML}}=\underset{\theta}{\arg \max } \sum_{i=1}^{m} \log P\left(\boldsymbol{y}^{(i)} | \boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right)
$$

### 5.3 最大似然的理想性质

- 一致性：当样本数目$m\rightarrow \infty$时，就收敛率而言是最好的渐进估计。
  - 其成立条件是：
    - 真实分布$p_{data}$必须在模型族$p_{model}$中
    - 真实分布$p_{data}$必须对应一个$\theta$
- 统计效率：高

由于以上两点原因，其为机器学习的首选估计方法。

## 6.贝叶斯统计

