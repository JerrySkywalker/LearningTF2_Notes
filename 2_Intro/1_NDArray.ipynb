{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2.0.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NDArray 相关操作"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "本节目标：了解如何对内存中的数据进行操作。\n",
    "\n",
    "在tensorflow中，tensor是一个类，也是存储和变换数据的主要工具。如果你之前用过NumPy，你会发现tensor和NumPy的多维数组非常类似。然而，tensor提供GPU计算和自动求梯度等更多功能，这些使tensor更加适合深度学习。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.常见的数组操作\n",
    "常用数组操作有以下几个函数\n",
    "- range(n)   生成一个0~n-1的n个数构成的一个数组/向量\n",
    "- shape属性 获取向量的形状\n",
    "- len(x)    获取向量的形状\n",
    "- reshape(a，b，c，...) 将向量重新排列成a*b*c*...的一个张量\n",
    "\n",
    "我们先介绍NDArray的最基本功能，我们用arange函数创建一个行向量。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(12,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x = tf.constant(range(12))\n",
    "\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=315, shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 93
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这时返回了一个tensor实例，其中包含了从0开始的12个连续整数。\n",
    "我们可以通过shape属性来获取tensor实例的形状。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([12])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 94
    }
   ],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们也能够通过len得到tensor实例中元素（element）的总数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 95
    }
   ],
   "source": [
    "len(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面使用reshape函数把行向量x的形状改为(3, 4)，也就是一个3行4列的矩阵，并记作X。除了形状改变之外，X中的元素保持不变。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=317, shape=(3, 4), dtype=int32, numpy=\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 96
    }
   ],
   "source": [
    "X = tf.reshape(x,(3,4))\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注意X属性中的形状发生了变化。上面x.reshape((3, 4))也可写成x.reshape((-1, 4))或x.reshape((3, -1))。由于x的元素个数是已知的，这里的-1是能够通过元素个数和其他维度的大小推断出来的。\n",
    "\n",
    "接下来，我们创建一个各元素为0，形状为(2, 3, 4)的张量。实际上，之前创建的向量和矩阵都是特殊的张量。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=320, shape=(2, 3, 4), dtype=float32, numpy=\narray([[[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 97
    }
   ],
   "source": [
    "tf.zeros((2,3,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "类似地，我们可以创建各元素为1的张量。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=323, shape=(3, 4), dtype=float32, numpy=\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 98
    }
   ],
   "source": [
    "tf.ones((3,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们也可以通过Python的列表（list）指定需要创建的tensor中每个元素的值。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=324, shape=(3, 4), dtype=int32, numpy=\narray([[2, 1, 4, 3],\n       [1, 2, 3, 4],\n       [4, 3, 2, 1]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 99
    }
   ],
   "source": [
    "Y = tf.constant([[2,1,4,3],[1,2,3,4],[4,3,2,1]])\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "有些情况下，我们需要随机生成tensor中每个元素的值。下面我们创建一个形状为(3, 4)的tensor。它的每个元素都随机采样于均值为0、标准差为1的正态分布。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=330, shape=(3, 4), dtype=float32, numpy=\narray([[ 0.7014324 ,  1.8282495 , -0.2024707 ,  0.8965961 ],\n       [-0.89472026,  0.5841548 , -0.3773617 ,  1.6393725 ],\n       [ 0.04045719,  0.02432128,  0.6969391 ,  0.5801539 ]],\n      dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 100
    }
   ],
   "source": [
    "tf.random.normal(shape=[3,4], mean=0, stddev=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 运算法则"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tensor支持大量的运算符（operator）。例如，我们可以对之前创建的两个形状为(3, 4)的tensor做按元素加法。所得结果形状不变。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=331, shape=(3, 4), dtype=int32, numpy=\narray([[ 2,  2,  6,  6],\n       [ 5,  7,  9, 11],\n       [12, 12, 12, 12]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 101
    }
   ],
   "source": [
    "X + Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "按元素乘法："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=332, shape=(3, 4), dtype=int32, numpy=\narray([[ 0,  1,  8,  9],\n       [ 4, 10, 18, 28],\n       [32, 27, 20, 11]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 102
    }
   ],
   "source": [
    "X * Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "按元素除法："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=335, shape=(3, 4), dtype=float64, numpy=\narray([[ 0.  ,  1.  ,  0.5 ,  1.  ],\n       [ 4.  ,  2.5 ,  2.  ,  1.75],\n       [ 2.  ,  3.  ,  5.  , 11.  ]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 103
    }
   ],
   "source": [
    "X / Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "按元素做指数运算：tf.cast用来进行数据转换。\n",
    "\n",
    "cast定义：\n",
    "\n",
    "cast(x, dtype, name=None)\n",
    "\n",
    "    第一个参数 x:   待转换的数据（张量）\n",
    "    第二个参数 dtype： 目标数据类型\n",
    "    第三个参数 name： 可选参数，定义操作的名称\n",
    "\n",
    "    DT_FLOAT\t    tf.float32\t        32 位浮点数.\n",
    "    DT_DOUBLE\t    tf.float64\t        64 位浮点数.\n",
    "    DT_INT64\t    tf.int64\t        64 位有符号整型.\n",
    "    DT_INT32\t    tf.int32\t        32 位有符号整型.\n",
    "    DT_INT16\t    tf.int16\t        16 位有符号整型.\n",
    "    DT_INT8\t            tf.int8\t        8 位有符号整型.\n",
    "    DT_UINT8\t    tf.uint8\t        8 位无符号整型.\n",
    "    DT_STRING\t    tf.string\t        可变长度的字节数组.每一个张量元素都是一个字节数组.\n",
    "    DT_BOOL\t            tf.bool\t        布尔型.\n",
    "    DT_COMPLEX64\t    tf.complex64    由两个32位浮点数组成的复数:实数和虚数.\n",
    "    DT_QINT32\t    tf.qint32\t    用于量化Ops的32位有符号整型.\n",
    "    DT_QINT8\t    tf.qint8\t    用于量化Ops的8位有符号整型.\n",
    "    DT_QUINT8\t    tf.quint8\t    用于量化Ops的8位无符号整型."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=337, shape=(3, 4), dtype=float32, numpy=\narray([[ 7.389056 ,  2.7182817, 54.59815  , 20.085537 ],\n       [ 2.7182817,  7.389056 , 20.085537 , 54.59815  ],\n       [54.59815  , 20.085537 ,  7.389056 ,  2.7182817]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 104
    }
   ],
   "source": [
    "Y = tf.cast(Y, tf.float32)\n",
    "tf.exp(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "除了按元素计算外，我们还可以使用matmul函数做矩阵乘法。下面将X与Y的转置做矩阵乘法。由于X是3行4列的矩阵，Y转置为4行3列的矩阵，因此两个矩阵相乘得到3行3列的矩阵。\n",
    "\n",
    "tf.transpose进行转置\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=341, shape=(3, 3), dtype=int32, numpy=\narray([[ 18,  20,  10],\n       [ 58,  60,  50],\n       [ 98, 100,  90]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 105
    }
   ],
   "source": [
    "Y = tf.cast(Y, tf.int32)\n",
    "tf.matmul(X, tf.transpose(Y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们也可以将多个tensor连结（concatenate）。下面分别在行上（维度0，即形状中的最左边元素）和列上（维度1，即形状中左起第二个元素）连结两个矩阵。可以看到，输出的第一个tensor在维度0的长度（ 6 ）为两个输入矩阵在维度0的长度之和（ 3+3 ），而输出的第二个tensor在维度1的长度（ 8 ）为两个输入矩阵在维度1的长度之和（ 4+4 ）。\n",
    "\n",
    "tf.concat(\n",
    "    values,\n",
    "    axis,\n",
    "    name='concat'\n",
    ")\n",
    "\n",
    "    values 表示拼接的数据\n",
    "    axis   表示拼接的维度"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: id=343, shape=(6, 4), dtype=int32, numpy=\n array([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [ 2,  1,  4,  3],\n        [ 1,  2,  3,  4],\n        [ 4,  3,  2,  1]])>,\n <tf.Tensor: id=345, shape=(3, 8), dtype=int32, numpy=\n array([[ 0,  1,  2,  3,  2,  1,  4,  3],\n        [ 4,  5,  6,  7,  1,  2,  3,  4],\n        [ 8,  9, 10, 11,  4,  3,  2,  1]])>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 106
    }
   ],
   "source": [
    "tf.concat([X,Y],axis = 0), tf.concat([X,Y],axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用条件判断式可以得到元素为0或1的新的tensor。以X == Y为例，如果X和Y在相同位置的条件判断为真（值相等），那么新的tensor在相同位置的值为1；反之为0。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=346, shape=(3, 4), dtype=bool, numpy=\narray([[False,  True, False,  True],\n       [False, False, False, False],\n       [False, False, False, False]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 107
    }
   ],
   "source": [
    "tf.equal(X,Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "对tensor中的所有元素求和得到只有一个元素的tensor。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=348, shape=(), dtype=int32, numpy=66>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 108
    }
   ],
   "source": [
    "tf.reduce_sum(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=354, shape=(), dtype=float32, numpy=22.494444>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 109
    }
   ],
   "source": [
    "X = tf.cast(X, tf.float32)\n",
    "tf.norm(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.广播机制 broadcasting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "前面我们看到如何对两个形状相同的tensor做按元素运算。当对两个形状不同的tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个tensor形状相同后再按元素运算。\n",
    "\n",
    "定义两个tensor："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: id=357, shape=(3, 1), dtype=int32, numpy=\n array([[0],\n        [1],\n        [2]])>,\n <tf.Tensor: id=360, shape=(1, 2), dtype=int32, numpy=array([[0, 1]])>)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 110
    }
   ],
   "source": [
    "A = tf.reshape(tf.constant(range(3)), (3,1))\n",
    "B = tf.reshape(tf.constant(range(2)), (1,2))\n",
    "A, B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "由于A和B分别是3行1列和1行2列的矩阵，如果要计算A + B，那么A中第一列的3个元素被广播（复制）到了第二列，而B中第一行的2个元素被广播（复制）到了第二行和第三行。如此，就可以对2个3行2列的矩阵按元素相加。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=361, shape=(3, 2), dtype=int32, numpy=\narray([[0, 1],\n       [1, 2],\n       [2, 3]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 111
    }
   ],
   "source": [
    "A + B"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 索引操作 indexing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在tensor中，索引（index）代表了元素的位置。tensor的索引从0开始逐一递增。例如，一个3行2列的矩阵的行索引分别为0、1和2，列索引分别为0和1。\n",
    "\n",
    "在下面的例子中，我们指定了tensor的行索引截取范围[1:3]。依据左闭右开指定范围的惯例，它截取了矩阵X中行索引为1和2的两行。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=365, shape=(2, 4), dtype=float32, numpy=\narray([[ 4.,  5.,  6.,  7.],\n       [ 8.,  9., 10., 11.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 112
    }
   ],
   "source": [
    "X[1:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以指定tensor中需要访问的单个元素的位置，如矩阵中行和列的索引，并为该元素重新赋值。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'UnreadVariable' shape=(3, 4) dtype=float32, numpy=\narray([[ 0.,  1.,  2.,  3.],\n       [ 4.,  5.,  9.,  7.],\n       [ 8.,  9., 10., 11.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 113
    }
   ],
   "source": [
    "X = tf.Variable(X)\n",
    "X[1,2].assign(9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "当然，我们也可以截取一部分元素，并为它们重新赋值。在下面的例子中，我们为行索引为1的每一列元素重新赋值。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\narray([[ 0.,  1.,  2.,  3.],\n       [ 4.,  5.,  9.,  7.],\n       [ 8.,  9., 10., 11.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 114
    }
   ],
   "source": [
    "X = tf.Variable(X)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'UnreadVariable' shape=(3, 4) dtype=float32, numpy=\narray([[ 0.,  1.,  2.,  3.],\n       [12., 12., 12., 12.],\n       [ 8.,  9., 10., 11.]], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 115
    }
   ],
   "source": [
    "X[1:2,:].assign(tf.ones(X[1:2,:].shape, dtype = tf.float32)*12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5 节省内存的相关操作"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在前面的例子里我们对每个操作新开内存来存储运算结果。举个例子，即使像Y = X + Y这样的运算，我们也会新开内存，然后将Y指向新内存。为了演示这一点，我们可以使用Python自带的id函数：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 116
    }
   ],
   "source": [
    "X = tf.Variable(X)\n",
    "Y = tf.cast(Y, dtype=tf.float32)\n",
    "\n",
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果想指定结果到特定内存，我们可以使用前面介绍的索引来进行替换操作。在下面的例子中，我们先通过zeros_like创建和Y形状相同且元素为0的tensor，记为Z。接下来，我们把X + Y的结果通过[:]写进Z对应的内存中。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 117
    }
   ],
   "source": [
    "Z = tf.Variable(tf.zeros_like(Y))\n",
    "before = id(Z)\n",
    "Z[:].assign(X + Y)\n",
    "id(Z) == before"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "实际上，上例中我们还是为X + Y开了临时内存来存储计算结果，再复制到Z对应的内存。如果想避免这个临时内存开销，我们可以使用运算符全名函数中的out参数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 118
    }
   ],
   "source": [
    "Z = tf.add(X, Y)\n",
    "id(Z) == before"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果X的值在之后的程序中不会复用，我们也可以用 X[:] = X + Y 或者 X += Y 来减少运算的内存开销。\n",
    "\n",
    " X: = X + Y ，这里X:指明操作内存的位置为X的位置，不新开内存"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 119
    }
   ],
   "source": [
    "before = id(X)\n",
    "X.assign_add(Y)\n",
    "id(X) == before"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. 转换关系"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以通过array函数和asnumpy函数令数据在NDArray和NumPy格式之间相互变换。\n",
    "\n",
    "下面将NumPy实例变换成tensor实例。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: id=430, shape=(2, 3), dtype=float64, numpy=\narray([[1., 1., 1.],\n       [1., 1., 1.]])>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 120
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "P = np.ones((2,3))\n",
    "D = tf.constant(P)\n",
    "D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "再将NDArray实例变换成NumPy实例。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 1., 1.],\n       [1., 1., 1.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 121
    }
   ],
   "source": [
    "np.array(D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}